steps:

- name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
  id: Read cluster intent, create cluster, and configure configsync
  script: |
    #!/usr/bin/env bash
    # shellcheck disable=SC2155
    set +x
    set -o pipefail

    HARDWARE_MANAGEMENT_API_ENDPOINT="https://gdchardwaremanagement.googleapis.com"
    if [[ -n "${HARDWARE_MANAGEMENT_API_ENDPOINT_OVERRIDE}" ]]; then
      HARDWARE_MANAGEMENT_API_ENDPOINT=${HARDWARE_MANAGEMENT_API_ENDPOINT_OVERRIDE}
    fi
    HARDWARE_MANAGEMENT_API_VERSION="v1alpha"

    function die() {
      step=$1
      details=$2
      echo "$step"
      echo "$details"
      echo "Cluster Creation Failed: $CLUSTER_NAME"

      if [[ "$MAX_RETRIES" -eq 0 ]]; then
        echo "Marking zone as failed"
        zone_signal $ZONE_ID FACTORY_TURNUP_CHECKS_FAILED "$step" "$details"
      else
        # Will include the current build as well
        BUILD_COUNT=$(gcloud builds list --filter "tags='$STORE_ID' AND substitutions.TRIGGER_NAME='$TRIGGER_NAME'" --region us-central1 --format="csv[no-heading](name)" | wc -l)

        if [[ "$BUILD_COUNT" -gt "$MAX_RETRIES" ]]; then
          echo "Current build count $BUILD_COUNT exceed max retries $MAX_RETRIES. Marking zone as failed"
          zone_signal $ZONE_ID FACTORY_TURNUP_CHECKS_FAILED "$step" "$details"
        else
          echo "Current build count $BUILD_COUNT is <= max retries $MAX_RETRIES. Skipping for next retry"
        fi
      fi

      exit 1
    }

    log_build_step() {
      message=$1
      echo $message

      zone_signal $ZONE_ID FACTORY_TURNUP_CHECKS_STARTED "$message"
    }

    # Sets the `UNDER_FACTORY_CHECKS` to either true if ZoneState is ready, started, or failed
    # or false for all other ZoneStates or for provisioning that bypasses the ZoneState.
    function set_factory_check_flag() {

      zone_store_path=$1

      [[ -n "${UNDER_FACTORY_CHECKS}" ]] && { return; } # UNDER_FACTORY_CHECKS already set
      [[ -z "${zone_store_path}" ]] && { export UNDER_FACTORY_CHECKS=FALSE; echo "zone signaling disabled"; return ; }

      ZONE_URI="${HARDWARE_MANAGEMENT_API_ENDPOINT}/${HARDWARE_MANAGEMENT_API_VERSION}/${zone_store_path}"

      out=$(curl -f -H "Authorization: Bearer $(gcloud auth print-access-token)" \
            -H "Content-Type: application/json" \
            -X GET \
            "${ZONE_URI}" -s | jq '.state' -r)

      if [[ $? -ne 0 ]]; then
        die "Failed to signal the zone state"
      fi

      if [[ "$out" == "READY_FOR_CUSTOMER_FACTORY_TURNUP_CHECKS" || \
            "$out" == "CUSTOMER_FACTORY_TURNUP_CHECKS_STARTED" || \
            "$out" == "CUSTOMER_FACTORY_TURNUP_CHECKS_FAILED" ]]; then
        echo "zone signaling enabled"
        export UNDER_FACTORY_CHECKS=TRUE
      else
        echo "zone signaling disabled"
        export UNDER_FACTORY_CHECKS=FALSE
      fi
    }

    function zone_signal() {
      zone_store_path=$1
      state_signal=$2
      step=$3
      details=$4

      [[ -z "${zone_store_path}" ]] && { echo "zone_store_path not provided"; return ; }

      if [[ "$UNDER_FACTORY_CHECKS" == "FALSE" ]]; then
        return;
      fi

      if [[ "$OPT_IN_BUILD_MESSAGES" != "TRUE" ]]; then
        step=""
        details=""
      fi

      SIGNAL_URI="${HARDWARE_MANAGEMENT_API_ENDPOINT}/${HARDWARE_MANAGEMENT_API_VERSION}/${zone_store_path}:signal"

      if [[ $state_signal == "FACTORY_TURNUP_CHECKS_STARTED" ]]; then
        state_signal_payload="{\"state_signal\": \"${state_signal}\", \"step\": \"${step}\"}"
      elif [[ $state_signal == "FACTORY_TURNUP_CHECKS_FAILED" ]]; then
        state_signal_payload="{\"state_signal\": \"${state_signal}\", \"step\": \"${step}\", \"details\": \"${details}\"}"
      else
        state_signal_payload="{\"state_signal\": \"${state_signal}\"}"
      fi

      out=$(curl -s -f -H "Authorization: Bearer $(gcloud auth print-access-token)" \
            -H "Content-Type: application/json" \
            -X POST \
            "${SIGNAL_URI}" \
            -d "$state_signal_payload")


      if [[ $? -ne 0 ]]; then
        die "Failed to signal the zone state"
      fi

      operation_id=$(echo $out | jq -r .name)
      URI="${HARDWARE_MANAGEMENT_API_ENDPOINT}/${HARDWARE_MANAGEMENT_API_VERSION}/${operation_id}"
      count=0
      max_retries=10
      while [[ ${count} -lt ${max_retries} ]]; do
        is_completed=$(curl -s -H "Authorization: Bearer $(gcloud auth print-access-token)" \
            "${URI}" | jq -r .done)
        [[ "${is_completed}" != "false" ]] && break
      done
    }

    function parse_csv_required() {
      input="$1"
      column="$2"

      output=$(echo "$input" | csvtool namedcol "$column" - | csvtool drop 1 - | tr -d '"')

      [[ $? -ne 0 ]] && die "Missing required parameter $2"

      if [ -z "$output" ]; then
        die "Empty required parameter $2"
      fi

      echo "$output"
    }

    function parse_csv_optional() {
      input="$1"
      column="$2"

      output=$(echo "$input" | csvtool namedcol "$column" - | csvtool drop 1 - | tr -d '"')

      echo "$output"
    }

    [[ -z "${STORE_ID}" ]] && die "STORE_ID not set"

    NODE_LOCATION=${ZONE}
    [[ -z "$NODE_LOCATION" ]] && die "ZONE not set"

    apt-get update
    apt-get install -y gettext-base csvtool jq

    TOKEN=$(gcloud secrets versions access latest --secret=$GIT_SECRET_ID --project $GIT_SECRETS_PROJECT_ID)
    git clone -b $SOURCE_OF_TRUTH_BRANCH https://oauth2:$TOKEN@$SOURCE_OF_TRUTH_REPO repo
    cp repo/$SOURCE_OF_TRUTH_PATH ./cluster-intent-registry.csv

    export CLUSTER_INTENT_ROW=$(awk -F , "\$1 == \"$STORE_ID\" || \$1 == \"\\\"$STORE_ID\\\"\"" cluster-intent-registry.csv)
    echo $CLUSTER_INTENT_ROW
    [[ -z "$CLUSTER_INTENT_ROW" ]] && die "Cluster intent not found for store $STORE_ID"
    export CLUSTER_INTENT_HEADER=$(head -1 cluster-intent-registry.csv)
    export CLUSTER_INTENT="$CLUSTER_INTENT_HEADER"$'\n'"$CLUSTER_INTENT_ROW"

    # Set parameters from cluster intent
    export MACHINE_PROJECT_ID=$(parse_csv_required "$CLUSTER_INTENT" "machine_project_id")
    export FLEET_PROJECT_ID=$(parse_csv_required "$CLUSTER_INTENT" "fleet_project_id")
    export CLUSTER_NAME=$(parse_csv_required "$CLUSTER_INTENT" "cluster_name")
    export LOCATION=$(parse_csv_required "$CLUSTER_INTENT" "location")
    export NODE_COUNT=$(parse_csv_required "$CLUSTER_INTENT" "node_count")
    export CLUSTER_IPV4_CIDR=$(parse_csv_required "$CLUSTER_INTENT" "cluster_ipv4_cidr")
    export SERVICES_IPV4_CIDR=$(parse_csv_required "$CLUSTER_INTENT" "services_ipv4_cidr")
    export EXTERNAL_LOAD_BALANCER_IPV4_ADDRESS_POOLS=$(parse_csv_required "$CLUSTER_INTENT" "external_load_balancer_ipv4_address_pools")
    export SYNC_REPO=$(parse_csv_required "$CLUSTER_INTENT" "sync_repo")
    export SYNC_BRANCH=$(parse_csv_required "$CLUSTER_INTENT" "sync_branch")
    export SYNC_DIR=$(parse_csv_required "$CLUSTER_INTENT" "sync_dir")
    export SECRETS_PROJECT_ID=$(parse_csv_required "$CLUSTER_INTENT" "secrets_project_id")
    export GIT_TOKEN_SECRETS_MANAGER_NAME=$(parse_csv_required "$CLUSTER_INTENT" "git_token_secrets_manager_name")
    export CLUSTER_VERSION=$(parse_csv_required "$CLUSTER_INTENT" "cluster_version")
    export MAINTENANCE_WINDOW_START=$(parse_csv_optional "$CLUSTER_INTENT" "maintenance_window_start")
    export MAINTENANCE_WINDOW_END=$(parse_csv_optional "$CLUSTER_INTENT" "maintenance_window_end")
    export MAINTENANCE_WINDOW_RECURRENCE=$(parse_csv_optional "$CLUSTER_INTENT" "maintenance_window_recurrence")
    export SUBNET_VLANS=$(parse_csv_optional "$CLUSTER_INTENT" "subnet_vlans")
    export ZONE_NAME_FROM_SOT=$(parse_csv_optional "$CLUSTER_INTENT" "zone_name")
    export LABELS=$(parse_csv_optional "$CLUSTER_INTENT" "labels")
    export ZONE_ID="projects/${MACHINE_PROJECT_ID}/locations/${LOCATION}/zones/${STORE_ID}"
    if [[ -n "${ZONE_NAME_FROM_SOT}" ]]; then
      set_factory_check_flag
    else
      set_factory_check_flag $ZONE_ID
    fi

    if [ -n "${EDGE_CONTAINER_API_ENDPOINT_OVERRIDE:-}" ]; then
      echo "Setting api_endpoint_overrides/edgecontainer to $EDGE_CONTAINER_API_ENDPOINT_OVERRIDE"
      gcloud config set api_endpoint_overrides/edgecontainer $EDGE_CONTAINER_API_ENDPOINT_OVERRIDE
    fi

    if [ -n "${GKEHUB_API_ENDPOINT_OVERRIDE:-}" ]; then
      echo "Setting api_endpoint_overrides/gkehub to $GKEHUB_API_ENDPOINT_OVERRIDE"
      gcloud config set api_endpoint_overrides/gkehub $GKEHUB_API_ENDPOINT_OVERRIDE
      GKEHUB_API_ENDPOINT="staging-gkehub.sandbox.googleapis.com"
    else
      GKEHUB_API_ENDPOINT="gkehub.googleapis.com"
    fi

    if [ -n "${EDGE_NETWORK_API_ENDPOINT_OVERRIDE:-}" ]; then
      echo "Setting api_endpoint_overrides/edgenetwork to $EDGE_NETWORK_API_ENDPOINT_OVERRIDE"
      gcloud config set api_endpoint_overrides/edgenetwork $EDGE_NETWORK_API_ENDPOINT_OVERRIDE
    fi

    log_build_step "Beginning provisioning"

    gcloud edge-cloud container clusters describe $CLUSTER_NAME --location $LOCATION \
        --project $FLEET_PROJECT_ID --verbosity none

    if [ $? -eq 0 ]; then
      log_build_step "Cluster already created, skipping to next step."
    else
      log_build_step "Creating cluster"

      # Create a new FD to support stdout,stderr to console + saving to bash variable
      # This is used to output the opid before the operation has completed
      exec 5>&1

      out=$(
        gcloud edge-cloud container clusters create $CLUSTER_NAME \
          --control-plane-node-location=$NODE_LOCATION \
          --control-plane-node-count=$NODE_COUNT \
          --cluster-ipv4-cidr=$CLUSTER_IPV4_CIDR \
          --services-ipv4-cidr=$SERVICES_IPV4_CIDR \
          --external-lb-ipv4-address-pools=$EXTERNAL_LOAD_BALANCER_IPV4_ADDRESS_POOLS \
          --control-plane-shared-deployment-policy=ALLOWED \
          --location=$LOCATION \
          --project=$FLEET_PROJECT_ID \
          --release-channel=NONE \
          --version $CLUSTER_VERSION \
          --offline-reboot-ttl=7d 2>&1 | tee /dev/fd/5
      )

      [[ $? -ne 0 ]] && die "Failure from gcloud edge-cloud container clusters" "$out"

    fi

    if [[ -z "${MAINTENANCE_WINDOW_START}" || -z ${MAINTENANCE_WINDOW_END} || \
            -z ${MAINTENANCE_WINDOW_RECURRENCE} ]]; then
      log_build_step "All maintenance window fields are not set, skipping"
      echo "MAINTENANCE_WINDOW_START=${MAINTENANCE_WINDOW_START}"
      echo "MAINTENANCE_WINDOW_END=${MAINTENANCE_WINDOW_END}"
      echo "MAINTENANCE_WINDOW_RECURRENCE=${MAINTENANCE_WINDOW_RECURRENCE}"
    else
      log_build_step "Setting maintenance window"
      out=$(gcloud edge-cloud container clusters update $CLUSTER_NAME \
          --project=$FLEET_PROJECT_ID \
          --location=$LOCATION \
          --maintenance-window-start=$MAINTENANCE_WINDOW_START \
          --maintenance-window-end=$MAINTENANCE_WINDOW_END \
          --maintenance-window-recurrence=$MAINTENANCE_WINDOW_RECURRENCE)
      [[ $? -ne 0 ]] && die "Maintenance window update failed" "$out"
    fi

    log_build_step "Initializing zone network"
    out=$(gcloud edge-cloud networking zones init $NODE_LOCATION \
      --project=$MACHINE_PROJECT_ID \
      --location=$LOCATION)

    [[ $? -ne 0 ]] && die "Zone network failed to initialize" "$out"

    log_build_step "Configuring zone subnets"
    for vlan in $(echo $SUBNET_VLANS | csvtool transpose -); do
      EXISTING_VLAN=$(gcloud edge-cloud networking subnets list --location $LOCATION \
          --zone $NODE_LOCATION --project $MACHINE_PROJECT_ID \
          --filter="VLANID=$vlan" --format="json")

      [[ $? -ne 0 ]] && die "Unable to query for subnets"

      if [ "$EXISTING_VLAN" = "[]" ]; then
        out=$(gcloud edge-cloud networking subnets create "network-$vlan" \
            --vlan-id=$vlan \
            --network=default \
            --location=$LOCATION \
            --zone=$NODE_LOCATION \
            --project $MACHINE_PROJECT_ID)
        [[ $? -ne 0 ]] && die "Subnet creation failed" "$out"
      else
        echo "VLAN $vlan already exists"
      fi
    done

    set -eE
    trap 'die "Error configuring cluster"' ERR

    if [ -n "$LABELS" ]; then
      log_build_step "Adding fleet membership labels"
      gcloud container fleet memberships update $CLUSTER_NAME --clear-labels --update-labels $LABELS
    fi

    export KUBECONFIG="$(pwd)/gateway-kubeconfig"
    gcloud container fleet memberships get-credentials $CLUSTER_NAME --project $FLEET_PROJECT_ID

    gsutil cp gs://$CLUSTER_INTENT_BUCKET/apply-spec.yaml.template .

    if [[ -n "$CS_VERSION" ]]; then
      export CS_VERSION_YAML="version: $CS_VERSION"
    fi

    envsubst < apply-spec.yaml.template > apply-spec.yaml

    log_build_step "Configuring configsync"
    gcloud config set project kr-9985-edgcmp-p
    gcloud secrets versions access latest --secret=$GIT_TOKEN_SECRETS_MANAGER_NAME \
        --project $SECRETS_PROJECT_ID >> $(pwd)/git-token

    kubectl create ns config-management-system --dry-run=client -o yaml | kubectl apply -f -

    kubectl create secret generic git-creds \
        --namespace="config-management-system" \
        --from-literal=username=kalaivani-kr --from-file=token=$(pwd)/git-token \
        --dry-run=client -o yaml | kubectl apply -f -

    gcloud alpha container hub config-management enable
    gcloud beta container fleet config-management apply --membership=$CLUSTER_NAME \
        --config=./apply-spec.yaml --project $FLEET_PROJECT_ID
    
    gcloud container fleet policycontroller enable --memberships=$CLUSTER_NAME  --project=$FLEET_PROJECT_ID
    gcloud container fleet policycontroller describe --memberships=$CLUSTER_NAME  --project=$FLEET_PROJECT_ID  
      
      gcloud config set project kr-9985-edgcmp-p
      gcloud secrets versions access latest --secret=robin-consumer-id \
        --project $SECRETS_PROJECT_ID >> $(pwd)/consumer-id
      gcloud secrets versions access latest --secret=robin-entitlement-id \
        --project $SECRETS_PROJECT_ID >> $(pwd)/entitlement-id
      gcloud secrets versions access latest --secret=robin-reporting-key \
        --project $SECRETS_PROJECT_ID >> $(pwd)/reporting-key
      gcloud secrets versions access latest --secret=jfrog-username \
        --project $SECRETS_PROJECT_ID >> $(pwd)/jfrog-username
      gcloud secrets versions access latest --secret=jfrog-password \
        --project $SECRETS_PROJECT_ID >> $(pwd)/jfrog-password

       kubectl create secret generic enterprise-sds-by-robin-license-603255 \
        --namespace="robin-admin" \
        --from-file=consumer-id=$(pwd)/consumer-id \
        --from-file=entitlement-id=$(pwd)/entitlement-id \
        --from-file=reporting-key=$(pwd)/reporting-key \
        --dry-run=client -o yaml | kubectl apply -f -

       kubectl create secret generic jfrog-creds \
        --namespace="config-management-system" \
        --from-file=username=$(pwd)/jfrog-username \
        --from-file=password=$(pwd)/jfrog-password \
        --dry-run=client -o yaml | kubectl apply -f -

    if [[ "${SKIP_IDENTITY_SERVICE}" == "FALSE" ]]; then
      log_build_step "Configuring Group RBAC"
      FLEET_PROJECT_NUMBER=$(gcloud projects describe $FLEET_PROJECT_ID --format='value(projectNumber)')
      kubectl patch clientconfig default -n kube-public --type=merge -p '{"spec":{"authentication":[{"google":{"audiences":["//'${GKEHUB_API_ENDPOINT}'/projects/'${FLEET_PROJECT_NUMBER}'/locations/global/memberships/'${CLUSTER_NAME}'"]},"name":"google-authentication-method"}]}}'
      log_build_step "Group RBAC applied"
    else
      log_build_step "Skipping Group RBAC setup"
    fi

    set +eE
    trap - ERR

    if [ -z "${SKIP_HEALTH_CHECK}" ]; then
      count=0
      max_retries=240 # 1200s/20min
      log_build_step "Waiting for health check resource to be created"
      while [[ ${count} -lt ${max_retries} ]]; do
        kubectl get healthchecks.validator.gdc.gke.io/default >/dev/null 2>&1 && break
        echo -n .
        sleep 5
        ((count++))
      done
      [[ ${count} -ge ${max_retries} ]] && die "Health check resource not created after 20min"

      log_build_step "Waiting for platform healthchecks to pass"
      kubectl wait healthchecks.validator.gdc.gke.io/default --for condition=PlatformHealthy \
          --timeout=1h || die "Platform is not healthy after 1h"

      # Calculate workload timeout by removing non-workload related buffer time from the over build timeout.
      # ($TIMEOUT_IN_SECONDS) - (1h for platform health) - (1h for cluster health)
      #                       - (10m for extra buffer) - (30m for vm wait)
      WORKLOAD_TIMEOUT="$(($TIMEOUT_IN_SECONDS-"9600"))"

      # log_build_step "Waiting for workload healthchecks to pass"
      # kubectl wait healthchecks.validator.gdc.gke.io/default --for condition=WorkloadsHealthy \
      #     --timeout="${WORKLOAD_TIMEOUT}s" || die "Workloads are not healthy after ${WORKLOAD_TIMEOUT}s"
    fi
    
    set -eE
    trap 'die "Error shutting down VMs"' ERR

    export VIRTCTL_VERSION=v1.2.2
    curl -L https://github.com/kubevirt/kubevirt/releases/download/${VIRTCTL_VERSION}/virtctl-${VIRTCTL_VERSION}-linux-amd64 -o virtctl
    chmod +x virtctl

    log_build_step "Waiting 30m before shutting down VMs"
    sleep 30m

    log_build_step "Shutting down running VMs"
    for vm in $(kubectl get vmi -n vm-workloads --no-headers | awk '{print $1}'); do
      echo "Shutting down $vm"
      ./virtctl stop -n vm-workloads $vm
    done

    set +eE
    trap - ERR

    if [ "${BART_CREATE_BUCKET}" = "TRUE" ]; then
      if [[ ! -z $(gcloud storage buckets describe gs://${CLUSTER_NAME}-bart-backup --project=${FLEET_PROJECT_ID}) ]]; then
        echo "GCS bucket already exists"
      else
        log_build_step "Creating and setting up new BART related GCS bucket"
        gcloud storage buckets create gs://${CLUSTER_NAME}-bart-backup --location=${LOCATION} --project=${FLEET_PROJECT_ID}
      fi
    else
      echo "Backups for this cluster is not enabled. Not creating GCS bucket."
    fi

    echo "Run Sanity Check"
    if gcloud edge-cloud container clusters describe $CLUSTER_NAME --location=$LOCATION; then
      sleep 1800
      sh -x repo/sanity_report_combine.sh
    else
      die "Cluster failed to build"
    fi    

    zone_signal $ZONE_ID FACTORY_TURNUP_CHECKS_PASSED

    echo "Cluster Creation Succeeded: $CLUSTER_NAME"

  env:
  - 'EDGE_CONTAINER_API_ENDPOINT_OVERRIDE=$_EDGE_CONTAINER_API_ENDPOINT_OVERRIDE'
  - 'EDGE_NETWORK_API_ENDPOINT_OVERRIDE=$_EDGE_NETWORK_API_ENDPOINT_OVERRIDE'
  - 'GKEHUB_API_ENDPOINT_OVERRIDE=$_GKEHUB_API_ENDPOINT_OVERRIDE'
  - 'HARDWARE_MANAGEMENT_API_ENDPOINT_OVERRIDE=$_HARDWARE_MANAGEMENT_API_ENDPOINT_OVERRIDE'
  - 'CLUSTER_INTENT_BUCKET=$_CLUSTER_INTENT_BUCKET'
  - 'SOURCE_OF_TRUTH_REPO=$_SOURCE_OF_TRUTH_REPO'
  - 'SOURCE_OF_TRUTH_BRANCH=$_SOURCE_OF_TRUTH_BRANCH'
  - 'SOURCE_OF_TRUTH_PATH=$_SOURCE_OF_TRUTH_PATH'
  - 'GIT_SECRET_ID=$_GIT_SECRET_ID'
  - 'GIT_SECRETS_PROJECT_ID=$_GIT_SECRETS_PROJECT_ID'
  - 'SKIP_HEALTH_CHECK=$_SKIP_HEALTH_CHECK'
  - 'SKIP_IDENTITY_SERVICE=$_SKIP_IDENTITY_SERVICE'
  - 'TIMEOUT_IN_SECONDS=$_TIMEOUT_IN_SECONDS'
  - 'STORE_ID=$_STORE_ID'
  - 'ZONE=$_ZONE'
  - 'CS_VERSION=$_CS_VERSION'
  - 'BART_CREATE_BUCKET=$_BART_CREATE_BUCKET'
  - 'MAX_RETRIES=$_MAX_RETRIES'
  - 'TRIGGER_NAME=$TRIGGER_NAME'
  - 'OPT_IN_BUILD_MESSAGES=$_OPT_IN_BUILD_MESSAGES'

options:
  logging: CLOUD_LOGGING_ONLY
tags:
- $_STORE_ID
- $_ZONE
